# LLM勉強会 〜基礎からエージェント設計まで〜
**Tomoki Yoshida (birder)🐦️ - DeNA AI技術開発部AIイノベーショングループ**
*2025-12-01 (月)*

## イントロダクション
### 背景と狙い
- **背景**: AIの普及で非エンジニアでもAPIを呼ぶだけでLLMを使えるようになったが、AIエンジニアの数は圧倒的に不足している。
- **狙い**:
    - 誰でも**LLMを組み合わせた設計**をイメージし、簡単なPoCができるようになること。
    - プロダクトの**フィードバックループの設計イメージ**を持つこと。

### 目指す姿
- **エンジニア**: 適切に問題を分解し、LLMを組み合わせて問題を解く（設計・実装）。
- **非エンジニア**: データを活用したプロダクト設計をイメージし、エンジニアと協業できる。

---

## 前半：基礎知識とプロンプトエンジニアリング

### LLMの仕組み
- **Next Token Prediction**: 次に来る単語を確率的に予測しているだけ。
- **Instruction Tuning**: 指示に従うようにチューニングされている。
- **Reasoning / Thinking**: 推論・思考してから応答するモデル（O1, Gemini-2.5-Pro, DeepSeek-R1等）が登場。

### プロンプトエンジニアリング
#### 基本テクニック
- Markdown/XML記法で構造化する。
- **入出力例（Few-shot）**を与える。
- ステップを明示する（Chain of Thought）。
- 役割付与、否定語より肯定文を使う。

#### 悪いプロンプト vs 良いプロンプト
- **悪い例**: 同じ指示の重複、重要な指示が埋もれる、長すぎる文章。
- **良い例**:
    - **構造化**: `# 必須要件`, `# 概要` などで見出しをつける。
    - **簡潔**: 重複や冗長な表現を削除する。
    - **強調**: 重要な部分だけ太字にする。

---

## 後半：データ活用とエージェント設計

### フィードバックループとパーソナライズ
プロダクトの成長にはユーザーからのフィードバックループが不可欠。
- **全体最適**: ファインチューニング（型や知識の注入）、強化学習（ニュアンスの調整）。
- **個別最適（パーソナライズ）**: **コンテキストエンジニアリング**、RAG。

### RAG (Retrieval-Augmented Generation)
外部データを検索してLLMに応答させる仕組み。
1.  **クエリ拡張**: ユーザーの質問を検索しやすい形に変換（補完、言い換え）。
2.  **ハイブリッド検索**: 全文検索（キーワード一致）とベクトル検索（意味の近さ）の組み合わせ。
3.  **リランキング**: 検索結果を関連度順に並び替え、上位のみ抽出。
4.  **グラウンディング**: 回答の根拠を提示。

### エージェント（Agent）
- **ReAct**: 思考(Thought) → 行動(Action) → 観察(Observation) のループで自律的にタスクをこなす。
- **Reflexion**: 結果を振り返り（内省）、次の行動を修正する。

---

## 便利なツール・周辺技術
- **n8n**: GUIでLLMワークフローを構築できるツール。
- **LangSmith / LangFuse**: LLMの実行トレース（ログ）、プロンプト管理、評価を行うためのプラットフォーム。

## まとめ
- 誰もがLLMを使った設計・PoCができる状態を目指した。
- 今日のコード（リポジトリ）をベースに、案件での実装を加速させよう。
